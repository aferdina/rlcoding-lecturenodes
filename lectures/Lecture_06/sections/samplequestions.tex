\section{Sample questions for exam}

\begin{frame}{Question 1}
    \textbf{Topic:} Optimising Reinforcement Learning Models: Callbacks

    \vspace{10pt}

    What is a callback in the context of training reinforcement learning models and how does its implementation work?

    \vspace{20pt}

    \textbf{Answer:} A \href{https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html}{callback} is a set of functions that will be called at given stages of the training procedure. You can use callbacks to access internal state of the RL model during training. It allows one to do monitoring, auto saving, model manipulation, progress bars, etc.

\end{frame}

\begin{frame}{Question 2}
    \textbf{Topic:} Neural Networks in Reinforcement Learning
    \vspace{10pt}

    Give two examples of the use of neural networks in connection with reinforcment learning.

    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 3}
    \textbf{Topic:} Implementing Neural Networks
    \vspace{10pt}

    Show schematically how the implementation of neural networks works in the context of the game environment in reinforcement learning. Name two additional parameters that can/must be defined for the creation of a neural network. 
\end{frame}
\begin{frame}
    \textbf{Answer:}
    \begin{enumerate}
        \item \textbf{Feature extrator for policy and value function:} The information about the observation space dimension is used to create a feature extractor for the policy and value function. Furthermore the type of feature extractor for the observation can be chosen (e.g flatten, convolutional, mlp, lstm, \dots). The result are neural net models of the form
        \[pi_{\text{feature}}: \mathbb{R}^{n_{\text{observation}}} \rightarrow \mathbb{R}^{n_{pi\text{features}}},\] and
        \[vi_{\text{feature}}: \mathbb{R}^{n_{\text{observation}}} \rightarrow \mathbb{R}^{n_{vi\text{features}}}\]
    \end{enumerate}
\end{frame}
\begin{frame}
    \textbf{Answer:}
    \begin{enumerate}[2.]
        \item \textbf{MLP Extractor:} In the context of Stable Baselines, an MLP extractor refers to a type of neural network architecture used for feature extraction in policy networks. Stable Baselines3 provides different types of policy networks, including those for images (CnnPolicies), various input features (MlpPolicies), and multiple inputs (MultiInputPolicies). For a 1D observation space, a fully connected network with multiple layers is used, where the number of units per layer varies depending on the algorithm used. The result are neural net models of the form
        \[pi_{\text{fully con}}: \mathbb{R}^{n_{pi \text{features}}} \rightarrow \mathbb{R}^{n_{pi \text{latent dim}}},\] and
        \[vi_{\text{fully con}}: \mathbb{R}^{n_{vi \text{features}}} \rightarrow \mathbb{R}^{n_{vi \text{latent dim}}}\]
    \end{enumerate}
\end{frame}
\begin{frame}
    \textbf{Answer:}
    \begin{enumerate}[3.]
        \item \textbf{Value Action mapping:} In the context of Stable Baselines, an MLP extractor refers to a type of neural network architecture used for feature extraction in policy networks. Stable Baselines3 provides different types of policy networks, including those for images (CnnPolicies), various input features (MlpPolicies), and multiple inputs (MultiInputPolicies). For a 1D observation space, a fully connected network with multiple layers is used, where the number of units per layer varies depending on the algorithm used. The result are neural net models of the form
        \[pi_{\text{fully con}}: \mathbb{R}^{n_{pi \text{features}}} \rightarrow \mathbb{R}^{n_{pi \text{latent dim}}},\] and
        \[vi_{\text{fully con}}: \mathbb{R}^{n_{vi \text{features}}} \rightarrow \mathbb{R}^{n_{vi \text{latent dim}}}\]
    \end{enumerate}
\end{frame}

\begin{frame}{Question 4}
    \textbf{Topic:} Monitoring Training Process: Tensorboard
    \vspace{10pt}

    What is a tensor board and what is it used for in the context of reinforcement learning? How is the information provided for the tensor board? 

    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 6}
    \textbf{Topic:} Storing Reinforcement Learning Parameter
    \vspace{10pt}

    Name 3 different elements that are stored when training reinforcement learning models. Describe the functions of the individual elements.

    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 7}
    \textbf{Topic:} Modelling Reinforcment Learning: GridWorld
    \vspace{10pt}

    Name 5 components that are needed to model the game GridWorld from the lecture. Also describe the implementation of the individual components.  
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 9}
    \textbf{Topic:} Implementing Multiarmed Bandit Environments
    \vspace{10pt}

    Create a UML class diagram for the implementation of a multi-armed bandit algorithm for an environment. Name all required methods and attributes. 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 10}
    \textbf{Topic:} Implementing Reinforcment Learning Models
    \vspace{10pt}

    Which mathematical model is described by the Python package `Gym`/`Gymnasium`. Name two main components of the package and how they are used. 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 11}
    \textbf{Topic:} Updating Neural Networks
    \vspace{10pt}

    Create a flowchart for the training update of neuroyal networks in `torch` in connection with an optimization function.
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 12}
    \textbf{Topic:} UML Class Diagram: Reinforcement Learning Algorithm
    \vspace{10pt}

    Create a UML class diagram for a Reinformcent Learning algorithm of your choice. 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 3}
    \textbf{Topic:} UML Class Diagram: Autonomous Driving
    \vspace{10pt}

    Create a UML class diagram for the game environment of the gym environment from the lecture.
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 13}
    \textbf{Topic:} Flowchart Diagram for Optimizing Multi-Armed Bandit Algorithms
    \vspace{10pt}

    Create a flowchart for optimizing multi-armed bandit algorithms. 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 14}
    \textbf{Topic:} Visualizing Reinforcement Learning Models
    \vspace{10pt}

    What is the Pygame package used for in the context of reinforcement learning and describe two features of the package. 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 15}
    \textbf{Topic:} Tabular Methods
    \vspace{10pt}

    Create a class diagram for the implementation of tabular methods from the lecture. What is the structure of the underlying decision rule? 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 16-20}
    \textbf{Topic:} Solid Principles
    \vspace{10pt}
    Describe one of the solid principles and explain the principle using the class diagram below. 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 21}
    \textbf{Topic:} Multi-Armed Bandits: Metrics
    \vspace{10pt}
    Specify the definition of a metric for the evaluation of multi-armed bandits.
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 22}
    \textbf{Topic:} Implementing Reinforcement Learning Algorithms
    \vspace{10pt}
    Specify the definition of a metric for the evaluation of multi-armed bandits.
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 23}
    \textbf{Topic:} Implementing Reinforcement Learning Environments
    
    \vspace{10pt}
    Which methods and attributes need to be defined for a gym environment. Which mathematical concepts are behind the individual attributes. What are the methods used for? 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 24}
    \textbf{Topic:} Implementing Reinforcement Learning Environments

    \vspace{10pt}
    Which methods and attributes need to be defined for a gym environment. Which mathematical concepts are behind the individual attributes. What are the methods used for? 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 25}
    \textbf{Topic:} Wrapper Classes and Reinforcement Learning Environments

    \vspace{10pt}
    How does a wrapper class work and what is it used for in the context of reinforcement learning environments?   
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 26}
    \textbf{Topic:} Hyperameter Tuning

    \vspace{10pt}
    Name three building blocks for hyperparameter optimization in the context of reinformcent learning.  
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}
\begin{frame}{Question 27}
    \textbf{Topic:} Policy Iteration Algorithm: Flow Diagram

    \vspace{10pt}
    Create a flowchart for the implementation of the algorithm. 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

\begin{frame}{Question 28}
    \textbf{Topic:} Dynyamic Programming: Flow Diagram

    \vspace{10pt}
    Create a flowchart for the implementation of the algorithm. 
    \vspace{20pt}

    \textbf{Answer:} [Insert answer or grading criteria]
\end{frame}

